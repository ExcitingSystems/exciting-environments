{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "import jax.numpy as jnp\n",
            "import jax\n",
            "import numpy as np\n",
            "import time\n",
            "import gymnasium as gym\n",
            "import sys\n",
            "sys.path.append(\"..\")\n",
            "import exciting_environments as excenvs\n",
            "import diffrax\n",
            "from exciting_environments import GymWrapper\n",
            "import jax_dataclasses as jdc\n",
            "from dataclasses import fields\n",
            "from exciting_environments.utils import MinMaxNormalization\n",
            "import os\n",
            "from pathlib import Path\n",
            "import pickle\n",
            "jax.config.update(\"jax_enable_x64\", True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [],
         "source": [
            "with open(\"data/sim_properties.pkl\", \"rb\") as f:\n",
            "    loaded_data = pickle.load(f)\n",
            "loaded_params = loaded_data[\"params\"]\n",
            "loaded_action_normalizations = loaded_data[\"action_normalizations\"]\n",
            "loaded_physical_normalizations = loaded_data[\"physical_normalizations\"]\n",
            "loaded_tau = loaded_data[\"tau\"]\n",
            "env = excenvs.make(\n",
            "    \"CartPole-v0\",\n",
            "    tau=loaded_tau,\n",
            "    solver=diffrax.Euler(),\n",
            "    static_params=loaded_params,\n",
            "    physical_normalizations=loaded_physical_normalizations,\n",
            "    action_normalizations=loaded_action_normalizations,\n",
            ")\n",
            "\n",
            "stored_observations = jnp.load(\"data/observations.npy\")\n",
            "actions_data = jnp.load(\"data/actions.npy\")\n",
            "state = env.generate_state_from_observation(stored_observations[0], env.env_properties)\n",
            "generated_observations = []\n",
            "generated_observations.append(stored_observations[0])\n",
            "for i in range(10000):\n",
            "    action = actions_data[i]\n",
            "    obs, state = env.step(state, action, env.env_properties)\n",
            "    generated_observations.append(obs)\n",
            "generated_observations = jnp.array(generated_observations)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "Array(True, dtype=bool)"
                  ]
               },
               "execution_count": 9,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "jnp.allclose(generated_observations, stored_observations, 1e-16)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "Array([[ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
                     "         0.00000000e+00],\n",
                     "       [ 0.00000000e+00, -1.52142068e-04, -1.00000000e+00,\n",
                     "        -2.28213103e-04],\n",
                     "       [-5.07140228e-08, -2.65808706e-04,  9.99999942e-01,\n",
                     "        -3.98713058e-04],\n",
                     "       ...,\n",
                     "       [ 3.39400971e-03,  6.48156987e-03,  9.99897298e-01,\n",
                     "         1.05608749e-02],\n",
                     "       [ 3.39617023e-03,  6.30010138e-03,  9.99899987e-01,\n",
                     "         1.02887315e-02],\n",
                     "       [ 3.39827026e-03,  6.53424452e-03,  9.99902607e-01,\n",
                     "         1.06400039e-02]], dtype=float64)"
                  ]
               },
               "execution_count": 10,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "generated_observations"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "Array([[ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
                     "         0.00000000e+00],\n",
                     "       [ 0.00000000e+00, -1.52142068e-04, -1.00000000e+00,\n",
                     "        -2.28213103e-04],\n",
                     "       [-5.07140228e-08, -2.65808706e-04,  9.99999942e-01,\n",
                     "        -3.98713058e-04],\n",
                     "       ...,\n",
                     "       [ 3.39400971e-03,  6.48156987e-03,  9.99897298e-01,\n",
                     "         1.05608749e-02],\n",
                     "       [ 3.39617023e-03,  6.30010138e-03,  9.99899987e-01,\n",
                     "         1.02887315e-02],\n",
                     "       [ 3.39827026e-03,  6.53424452e-03,  9.99902607e-01,\n",
                     "         1.06400039e-02]], dtype=float64)"
                  ]
               },
               "execution_count": 11,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "stored_observations"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [],
         "source": [
            "import json\n",
            "def safe_json_dump(obj, fp):\n",
            "    default = lambda o: f\"<<non-serializable: {type(o).__qualname__}>>\"\n",
            "    return json.dump(obj, fp, default=default)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [],
         "source": [
            "loaded_params = loaded_data[\"params\"]\n",
            "loaded_action_normalizations = loaded_data[\"action_normalizations\"]\n",
            "loaded_physical_normalizations = loaded_data[\"physical_normalizations\"]\n",
            "loaded_tau = loaded_data[\"tau\"]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "{'force': MinMaxNormalization(min=-20, max=20)}"
                  ]
               },
               "execution_count": 21,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "loaded_action_normalizations\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 20,
         "metadata": {},
         "outputs": [
            {
               "ename": "TypeError",
               "evalue": "Object of type MinMaxNormalization is not JSON serializable",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn[20], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m json_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: loaded_params,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction_normalizations\u001b[39m\u001b[38;5;124m\"\u001b[39m: loaded_action_normalizations,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphysical_normalizations\u001b[39m\u001b[38;5;124m\"\u001b[39m: loaded_physical_normalizations,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtau\u001b[39m\u001b[38;5;124m\"\u001b[39m: loaded_tau  \u001b[38;5;66;03m# tau ist vermutlich float oder 채hnlich\u001b[39;00m\n\u001b[1;32m      6\u001b[0m }\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/props_2.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 9\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(json_data, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
                  "File \u001b[0;32m~/.conda/envs/venv_dev/lib/python3.11/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    180\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(chunk)\n",
                  "File \u001b[0;32m~/.conda/envs/venv_dev/lib/python3.11/json/encoder.py:432\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
                  "File \u001b[0;32m~/.conda/envs/venv_dev/lib/python3.11/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
                  "File \u001b[0;32m~/.conda/envs/venv_dev/lib/python3.11/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
                  "File \u001b[0;32m~/.conda/envs/venv_dev/lib/python3.11/json/encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m _default(o)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
                  "File \u001b[0;32m~/.conda/envs/venv_dev/lib/python3.11/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
                  "\u001b[0;31mTypeError\u001b[0m: Object of type MinMaxNormalization is not JSON serializable"
               ]
            }
         ],
         "source": [
            "json_data = {\n",
            "    \"params\": loaded_params,\n",
            "    \"action_normalizations\": loaded_action_normalizations,\n",
            "    \"physical_normalizations\": loaded_physical_normalizations,\n",
            "    \"tau\": loaded_tau  # tau ist vermutlich float oder 채hnlich\n",
            "}\n",
            "\n",
            "with open(\"data/props_2.json\", \"w\") as f:\n",
            "    json.dump(json_data, f, indent=4)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 25,
         "metadata": {},
         "outputs": [],
         "source": [
            "import json\n",
            "from dataclasses import asdict\n",
            "\n",
            "# Alle inneren JDC-Objekte konvertieren\n",
            "action_norm_serialized = {\n",
            "    k: asdict(v) for k, v in loaded_action_normalizations.items()\n",
            "}\n",
            "physical_norm_serialized = {\n",
            "        k: asdict(v) for k, v in loaded_physical_normalizations.items()\n",
            "    }\n",
            "\n",
            "# Gleiches ggf. f체r andere 채hnlichen Strukturen\n",
            "data = {\n",
            "    \"params\": loaded_params,\n",
            "    \"action_normalizations\": action_norm_serialized,\n",
            "    \"physical_normalizations\": physical_norm_serialized,\n",
            "    \"tau\": loaded_tau,\n",
            "}\n",
            "\n",
            "with open(\"data/sim_properties.json\", \"w\") as f:\n",
            "    json.dump(data, f, indent=4)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def save_to_json(params, action_normalizations, physical_normalizations, tau, filename):\n",
            "    action_norm_serialized = {\n",
            "    k: asdict(v) for k, v in action_normalizations.items()\n",
            "    }\n",
            "    physical_norm_serialized = {\n",
            "            k: asdict(v) for k, v in physical_normalizations.items()\n",
            "        }\n",
            "    data = {\n",
            "        \"params\": params,\n",
            "        \"action_normalizations\": action_norm_serialized,\n",
            "        \"physical_normalizations\": physical_norm_serialized,\n",
            "        \"tau\": tau\n",
            "    }\n",
            "    with open(filename, 'w') as f:\n",
            "        json.dump(data, f, indent=4)\n",
            "\n",
            "def load_from_json(filename):\n",
            "    with open(filename, 'r') as f:\n",
            "        data = json.load(f)\n",
            "    \n",
            "    params= data[\"params\"]\n",
            "    action_norm_serialized = data[\"action_normalizations\"]\n",
            "    physical_norm_serialized = data[\"physical_normalizations\"]\n",
            "    tau = data[\"tau\"]\n",
            "    action_normalizations = {\n",
            "        key: MinMaxNormalization(**value)\n",
            "        for key, value in action_norm_serialized.items()\n",
            "    }\n",
            "    physical_normaliztions = {\n",
            "        key: MinMaxNormalization(**value)\n",
            "        for key, value in physical_norm_serialized.items()\n",
            "    }\n",
            "    return params, action_normalizations, physical_normaliztions, tau"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "venv_dev",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.9"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
