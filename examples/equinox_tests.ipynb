{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e55cd4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "from abc import abstractmethod\n",
    "from functools import partial\n",
    "from dataclasses import fields\n",
    "from typing import Callable\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.tree_util import tree_flatten, tree_unflatten, tree_structure, tree_leaves\n",
    "import equinox as eqx\n",
    "import diffrax\n",
    "import numpy as np\n",
    "import chex\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "10ccfabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoreEnvironment(eqx.Module):\n",
    "    tau: jax.Array #= eqx.field(static=True)\n",
    "    _solver: diffrax.AbstractSolver #= eqx.field(static=True)\n",
    "    env_properties: eqx.Module #= eqx.field(static=True)\n",
    "    in_axes_env_properties: eqx.Module #= eqx.field(static=True)\n",
    "    action_dim: int #= eqx.field(static=True) \n",
    "    physical_state_dim: int #= eqx.field(static=True)\n",
    "\n",
    "    \"\"\"\n",
    "    Core Structure of provided Environments. Any new environments needs to inherit from this class\n",
    "    and implement its abstract properties and methods.\n",
    "\n",
    "    The simulations are all done with physical state space models. That means that the underlying description\n",
    "    of the system is given through the differential equation describing the relationship between\n",
    "    the change of the physical state x(t) w.r.t. the time as a function of the physical state and the\n",
    "    input/action u(t) applied:\n",
    "\n",
    "    dx(t)/dt = f(x(t), u(t)).\n",
    "\n",
    "    The actual outputs of these simulations are discretized from this equation through the use of\n",
    "    ODE solvers.\n",
    "\n",
    "    NOTE: There is a difference between the state of the environment and the physical state x(t)\n",
    "    of the underlying system. The former can also hold various helper variables such as PRNGKeys\n",
    "    for stochastic environments, while the latter is reserved for the actual physical state of the\n",
    "    ODE. The physical state is only a part of the full state.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        env_properties: eqx.Module,\n",
    "        tau: float = 1e-4,\n",
    "        solver=diffrax.Euler(),\n",
    "    ):\n",
    "        \"\"\"Initialization of an environment.\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): Number of parallel environment simulations.\n",
    "            env_properties(eqx.Module): All parameters and properties of the environment.\n",
    "            tau (float): Duration of one control step in seconds. Default: 1e-4.\n",
    "            solver (diffrax.solver): ODE solver used to approximate the ODE solution.\n",
    "        \"\"\"\n",
    "        self.tau = tau\n",
    "        self._solver = solver\n",
    "        self.env_properties = env_properties\n",
    "        self.in_axes_env_properties = self.create_in_axes_dataclass(env_properties)\n",
    "        self.action_dim = len(fields(self.Action))\n",
    "        self.physical_state_dim = len(fields(self.PhysicalState))\n",
    "\n",
    "    @abstractmethod\n",
    "    class PhysicalState(eqx.Module):\n",
    "        \"\"\"The physical state x(t) of the underlying system and whose derivative\n",
    "        w.r.t. time is described in the underlying ODE.\n",
    "\n",
    "        The values stored in this dataclass are expected to be actual physical values\n",
    "        that are unnormalized and given in SI units.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    class Additions(eqx.Module):\n",
    "        \"\"\"\n",
    "        Stores additional environment state variables that may change over time.\n",
    "\n",
    "        These variables do not directly belong to the physical state but are\n",
    "        necessary for computations (e.g., internal buffers).\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    class StaticParams(eqx.Module):\n",
    "        \"\"\"\n",
    "        Holds static parameters of the environment that remain constant during simulation.\n",
    "\n",
    "        Examples:\n",
    "            - Length of a pendulum\n",
    "            - Capacitance of a capacitor\n",
    "            - Mass of an object\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    class Action(eqx.Module):\n",
    "        \"\"\"\n",
    "        Represents the input/action applied to the environment.\n",
    "\n",
    "        The action influences the system dynamics through the function `f(x(t), u(t))`.\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "\n",
    "    @partial(jax.jit, static_argnums=0)\n",
    "    @abstractmethod\n",
    "    def _ode_solver_step(self, state, action):\n",
    "        \"\"\"\n",
    "        Performs a single step of state evolution using the ODE solver.\n",
    "\n",
    "        Args:\n",
    "            state: The current state of the system.\n",
    "            action: The action applied at the current step.\n",
    "            static_params: Static parameters of the environment.\n",
    "\n",
    "        Returns:\n",
    "            state: The updated state after one simulation step.\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    @partial(jax.jit, static_argnums=[0, 3, 4])\n",
    "    @abstractmethod\n",
    "    def _ode_solver_simulate_ahead(self, init_state, actions, obs_stepsize, action_stepsize):\n",
    "        \"\"\"\n",
    "        Simulates a trajectory by applying a sequence of actions.\n",
    "\n",
    "        Args:\n",
    "            init_state: Initial state at the start of the trajectory.\n",
    "            actions: Sequence of actions to be applied (shape=(n_action_steps, action_dim)).\n",
    "            static_params: Static environment parameters.\n",
    "            obs_stepsize: Sampling interval for observations.\n",
    "            action_stepsize: Interval between consecutive action updates.\n",
    "\n",
    "        Returns:\n",
    "            states: Simulated trajectory states over time.\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    @partial(jax.jit, static_argnums=0)\n",
    "    @abstractmethod\n",
    "    def init_state(self, rng: chex.PRNGKey = None, vmap_helper=None):\n",
    "        \"\"\"\n",
    "        Generates an initial state for the environment.\n",
    "\n",
    "        Args:\n",
    "            env_properties: Environment properties.\n",
    "            rng (optional): Random key for random initialization.\n",
    "            vmap_helper (optional): Helper variable for vectorized computation.\n",
    "\n",
    "        Returns:\n",
    "            state: The initial state.\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    @partial(jax.jit, static_argnums=0)\n",
    "    @abstractmethod\n",
    "    def generate_observation(self, state):\n",
    "        \"\"\"\n",
    "        Generates an observation from the given state.\n",
    "\n",
    "        Args:\n",
    "            state: Current state of the environment.\n",
    "            env_properties: Environment properties.\n",
    "\n",
    "        Returns:\n",
    "            observation: The computed observation.\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    @partial(jax.jit, static_argnums=0)\n",
    "    @abstractmethod\n",
    "    def generate_state_from_observation(self, obs, key=None):\n",
    "        \"\"\"\n",
    "        Generates state from a given observation.\n",
    "\n",
    "        Args:\n",
    "            obs: The given observation.\n",
    "            env_properties: Environment properties.\n",
    "            key (optional): Random key.\n",
    "\n",
    "        Returns:\n",
    "            state: Computed state.\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    @partial(jax.jit, static_argnums=0)\n",
    "    @abstractmethod\n",
    "    def generate_reward(self, state, action):\n",
    "        \"\"\"\n",
    "        Computes the reward for a given state-action pair.\n",
    "\n",
    "        Args:\n",
    "            state: The current environment state.\n",
    "            action: The action applied at the current step.\n",
    "            env_properties: Environment properties.\n",
    "\n",
    "        Returns:\n",
    "            reward: Computed reward value.\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    @partial(jax.jit, static_argnums=0)\n",
    "    @abstractmethod\n",
    "    def generate_truncated(self, state):\n",
    "        \"\"\"\n",
    "        Computes truncated flag for given state.\n",
    "\n",
    "        Args:\n",
    "            state: The current environment state.\n",
    "            env_properties: Environment properties.\n",
    "\n",
    "        Returns:\n",
    "            truncated: Computed truncated flag.\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    @partial(jax.jit, static_argnums=0)\n",
    "    @abstractmethod\n",
    "    def generate_terminated(self, state, reward):\n",
    "        \"\"\"\n",
    "        Computes terminated flag for given state and reward.\n",
    "\n",
    "        Args:\n",
    "            state: The current environment state.\n",
    "            reward: The reward for current state-action pair.\n",
    "            env_properties: Environment properties.\n",
    "\n",
    "        Returns:\n",
    "            terminated: Computed terminated flag.\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    class State(eqx.Module):\n",
    "        \"\"\"The state of the environment.\"\"\"\n",
    "\n",
    "        physical_state: eqx.Module\n",
    "        PRNGKey: jax.Array\n",
    "        additions: eqx.Module\n",
    "        reference: eqx.Module\n",
    "\n",
    "    class EnvProperties(eqx.Module):\n",
    "        \"\"\"The properties of the environment that stay constant during simulation.\"\"\"\n",
    "\n",
    "        physical_normalizations: eqx.Module\n",
    "        action_normalizations: eqx.Module\n",
    "        static_params: eqx.Module\n",
    "\n",
    "    def create_in_axes_dataclass(self, dataclass):\n",
    "\n",
    "        def filter_function(value):\n",
    "            if value is None:\n",
    "                return None\n",
    "            elif isinstance(value, list):\n",
    "                raise ValueError(\n",
    "                    f\"Leaf needs to be a jnp.array to have different setting per batch, but list is given.\"\n",
    "                )\n",
    "            elif jnp.isscalar(value):\n",
    "                return None\n",
    "            elif isinstance(value, jax.Array):\n",
    "                if value.shape[0] == self.batch_size:\n",
    "                    return 0\n",
    "                else:\n",
    "                    return None\n",
    "            else:\n",
    "                raise ValueError(f\"Leaf needs to be a scalar, jnp.array, but {type(value)} is given.\")\n",
    "\n",
    "        dataclass_in_axes = jax.tree.map(filter_function, dataclass)\n",
    "        return dataclass_in_axes\n",
    "\n",
    "    def repeat_values(self, x, n_repeat):\n",
    "        \"\"\"Repeats the values of x n_repeat times.\"\"\"\n",
    "        if x == None:\n",
    "            return None\n",
    "        elif isinstance(x, tuple):\n",
    "            return tuple(self.repeat_values(i, n_repeat) for i in x)\n",
    "        elif isinstance(x, jax.numpy.ndarray):\n",
    "            return jnp.full(n_repeat, x)\n",
    "        elif isinstance(x, float) or isinstance(x, bool):\n",
    "            return jnp.full(n_repeat, x)\n",
    "        else:\n",
    "            raise ValueError(f\"State needs to consist of jnp.array, tuple, float or bool, but {type(x)} is given.\")\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def normalize_state(self, state):\n",
    "        \"\"\"\n",
    "        Normalizes the state using predefined normalization parameters.\n",
    "\n",
    "        Args:\n",
    "            state: Current environment state.\n",
    "            env_properties: Environment properties containing normalization parameters.\n",
    "\n",
    "        Returns:\n",
    "            norm_state: Normalized state.\n",
    "        \"\"\"\n",
    "        env_properties = self.env_properties\n",
    "        physical_normalizations = env_properties.physical_normalizations\n",
    "\n",
    "        new_physical_state = jax.tree.map(\n",
    "            lambda value, norm: norm.normalize(value),\n",
    "            state.physical_state,\n",
    "            physical_normalizations,\n",
    "        )\n",
    "        new_reference = jax.tree.map(\n",
    "            lambda value, norm: norm.normalize(value),\n",
    "            state.reference,\n",
    "            physical_normalizations,\n",
    "        )\n",
    "        new_state = eqx.tree_at(\n",
    "            lambda s: (s.physical_state, s.reference),\n",
    "            state,\n",
    "            (new_physical_state, new_reference),\n",
    "        )\n",
    "\n",
    "        return new_state\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def denormalize_state(self, norm_state):\n",
    "        \"\"\"\n",
    "        Denormalizes a given normalized state.\n",
    "\n",
    "        Args:\n",
    "            norm_state: The normalized state to be converted back.\n",
    "            env_properties: Environment properties containing normalization parameters.\n",
    "\n",
    "        Returns:\n",
    "            state: The denormalized state.\n",
    "        \"\"\"\n",
    "        env_properties = self.env_properties\n",
    "        physical_normalizations = env_properties.physical_normalizations\n",
    "\n",
    "        new_physical_state = jax.tree.map(\n",
    "            lambda value, norm: norm.denormalize(value),\n",
    "            norm_state.physical_state,\n",
    "            physical_normalizations,\n",
    "        )\n",
    "        new_reference = jax.tree.map(\n",
    "            lambda value, norm: norm.denormalize(value),\n",
    "            norm_state.reference,\n",
    "            physical_normalizations,\n",
    "        )\n",
    "        new_state = eqx.tree_at(\n",
    "            lambda s: (s.physical_state, s.reference),\n",
    "            norm_state,\n",
    "            (new_physical_state, new_reference),\n",
    "        )\n",
    "\n",
    "        return new_state\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def denormalize_action(self, action_norm):\n",
    "        \"\"\"\n",
    "        Denormalizes a given normalized action.\n",
    "\n",
    "        Args:\n",
    "            action_norm: The normalized action to be denormalized.\n",
    "            env_properties: Environment properties containing normalization parameters.\n",
    "\n",
    "        Returns:\n",
    "            action: The denormalized action.\n",
    "        \"\"\"\n",
    "        env_properties = self.env_properties\n",
    "        normalizations = env_properties.action_normalizations\n",
    "        norm_objects = [getattr(normalizations, name) for name in normalizations.__annotations__]\n",
    "\n",
    "        denorm_values = jnp.array([norm.denormalize(val) for norm, val in zip(norm_objects, action_norm)])\n",
    "\n",
    "        return denorm_values\n",
    "\n",
    "    def reset(\n",
    "        self,\n",
    "        rng: chex.PRNGKey = None,\n",
    "        initial_state: eqx.Module = None,\n",
    "        vmap_helper=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Resets environment to default, random or passed initial state.\n",
    "\n",
    "        Args:\n",
    "            env_properties: Environment properties.\n",
    "            rng (optional): Random key for random initialization.\n",
    "            initial_state (optional): The initial_state to which the environment will be reset.\n",
    "            vmap_helper (optional): Helper variable for vectorized computation.\n",
    "\n",
    "        Returns:\n",
    "            obs: Observation of initial state.\n",
    "            state: The initial state.\n",
    "        \"\"\"\n",
    "        if initial_state is not None:\n",
    "            assert tree_structure(self.init_state()) == tree_structure(\n",
    "                initial_state\n",
    "            ), f\"initial_state should have the same dataclass structure as init_state()\"\n",
    "            state = initial_state\n",
    "        else:\n",
    "            state = self.init_state(rng)\n",
    "        obs = self.generate_observation(state)\n",
    "\n",
    "        return obs, state\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def step(self, state, action_norm):\n",
    "        \"\"\"Computes one JAX-JIT compiled simulation step for one batch.\n",
    "\n",
    "        Args:\n",
    "            state: The current state of the simulation from which to calculate the next state.\n",
    "            action: The action to apply to the environment.\n",
    "            env_properties: Contains action/state constraints and static parameters.\n",
    "\n",
    "        Returns:\n",
    "            observation: The gathered observation.\n",
    "            state: New state for the next step.\n",
    "        \"\"\"\n",
    "        # assert action_norm.shape == (self.action_dim,), (\n",
    "        #     f\"The action needs to be of shape (action_dim,) which is \"\n",
    "        #     + f\"{(self.action_dim,)}, but {action_norm.shape} is given\"\n",
    "        # )\n",
    "\n",
    "        # physical_state_shape = jnp.array(tree_flatten(state.physical_state)[0]).T.shape\n",
    "\n",
    "        # assert physical_state_shape == (self.physical_state_dim,), (\n",
    "        #     \"The physical state needs to be of shape (physical_state_dim,) which is \"\n",
    "        #     + f\"{(self.physical_state_dim,)}, but {physical_state_shape} is given\"\n",
    "        # )\n",
    "\n",
    "        # denormalize action\n",
    "        action = self.denormalize_action(action_norm)\n",
    "\n",
    "        state = self._ode_solver_step(state, action)\n",
    "        obs = self.generate_observation(state)\n",
    "\n",
    "        return obs, state\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def sim_ahead(self, init_state, actions, obs_stepsize, action_stepsize):\n",
    "        \"\"\"Computes multiple JAX-JIT compiled simulation steps for one batch.\n",
    "\n",
    "        The length of the set of inputs together with the action_stepsize determine the\n",
    "        overall length of the simulation -> overall_time = actions.shape[0] * action_stepsize\n",
    "        The actions are interpolated with zero order hold inbetween their values.\n",
    "\n",
    "        Warning:\n",
    "            Depending on the underlying ODE solver (e.g., Tsit5 or other higher-order solvers),\n",
    "            intermediate evaluations during integration may internally access actions at future time steps.\n",
    "            Therefore `sim_ahead` is not guaranteed to be numerically equivalent to repeated\n",
    "            calls of `step`.\n",
    "\n",
    "\n",
    "        Args:\n",
    "            init_state: The initial state of the simulation\n",
    "            actions: A set of actions to be applied to the environment, the value changes every\n",
    "            action_stepsize (shape=(n_action_steps, action_dim))\n",
    "            env_properties: The constant properties of the simulation\n",
    "            obs_stepsize: The sampling time for the observations\n",
    "            action_stepsize: The time between changes in the input/action\n",
    "\n",
    "        Returns:\n",
    "            observations: The gathered observations.\n",
    "            states: The computed states during the simulated trajectory.\n",
    "            last_state: The last state of the simulations.\n",
    "        \"\"\"\n",
    "\n",
    "        # assert actions.ndim == 2, \"The actions need to have two dimensions: (n_action_steps, action_dim)\"\n",
    "        # assert (\n",
    "        #     actions.shape[-1] == self.action_dim\n",
    "        # ), f\"The last dimension does not correspond to the action dim which is {self.action_dim}, but {actions.shape[-1]} is given\"\n",
    "\n",
    "        # init_physical_state_shape = jnp.array(tree_flatten(init_state.physical_state)[0]).T.shape\n",
    "        # assert init_physical_state_shape == (self.physical_state_dim,), (\n",
    "        #     \"The initial physical state needs to be of shape (env.physical_state_dim,) which is \"\n",
    "        #     + f\"{(self.physical_state_dim,)}, but {init_physical_state_shape} is given\"\n",
    "        # )\n",
    "\n",
    "        # denormalize actions\n",
    "        actions = jax.vmap(self.denormalize_action, in_axes=(0, None))(actions)\n",
    "\n",
    "        single_state_struct = tree_structure(init_state)\n",
    "        # compute states trajectory for given actions\n",
    "        states = self._ode_solver_simulate_ahead(\n",
    "            init_state,\n",
    "            actions,\n",
    "            obs_stepsize,\n",
    "            action_stepsize,\n",
    "        )\n",
    "\n",
    "        # generate observations for all timesteps\n",
    "        observations = jax.vmap(self.generate_observation, in_axes=(0, None))(states)\n",
    "\n",
    "        # get last state so that the simulation can be continued from the end point\n",
    "        states_flatten, _ = tree_flatten(states)\n",
    "        last_state = tree_unflatten(single_state_struct, jnp.array(states_flatten)[:, -1])\n",
    "\n",
    "        return observations, states, last_state\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def generate_rew_trunc_term_ahead(self, states, actions):\n",
    "        \"\"\"\n",
    "        Computes rewards, truncated flags and terminated flags for data generated by `sim_ahead`.\n",
    "\n",
    "        Args:\n",
    "            states: A set of environment states over time, including the initial state.\n",
    "            actions: A set of actions applied sequentially (shape=(n_action_steps, action_dim)).\n",
    "            env_properties: The environment properties required for calculations.\n",
    "\n",
    "        Returns:\n",
    "            reward: Rewards computed for each step.\n",
    "            truncated: Truncated flags at each step.\n",
    "            terminated : Terminated flag at each step.\n",
    "        \"\"\"\n",
    "        # assert actions.ndim == 2, \"The actions need to have two dimensions: (n_action_steps, action_dim)\"\n",
    "        # assert (\n",
    "        #     actions.shape[-1] == self.action_dim\n",
    "        # ), f\"The last dimension does not correspond to the action dim which is {self.action_dim}, but {actions.shape[-1]} is given\"\n",
    "\n",
    "        actions = jax.vmap(self.denormalize_action, in_axes=(0, None))(actions)\n",
    "\n",
    "        states_flatten, struct = tree_flatten(states)\n",
    "\n",
    "        states_without_init_state = tree_unflatten(struct, jnp.array(states_flatten)[:, 1:])\n",
    "\n",
    "        reward = jax.vmap(self.generate_reward, in_axes=(0, 0, None))(\n",
    "            states_without_init_state,\n",
    "            jnp.expand_dims(\n",
    "                jnp.repeat(\n",
    "                    actions,\n",
    "                    int((jnp.array(states_flatten).shape[1] - 1) / actions.shape[0]),\n",
    "                ),\n",
    "                1,\n",
    "            ),\n",
    "        )\n",
    "        truncated = jax.vmap(self.generate_truncated, in_axes=(0, None))(states)\n",
    "        terminated = jax.vmap(self.generate_terminated, in_axes=(0, 0, None))(\n",
    "            states_without_init_state, reward\n",
    "        )\n",
    "        return reward, truncated, terminated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea52fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exciting_environments.utils import MinMaxNormalization\n",
    "def pendulum_soft_constraints(instance, state, action_norm):\n",
    "    state_norm = instance.normalize_state(state)\n",
    "    physical_state_norm = state_norm.physical_state\n",
    "    phys_soft_const = jax.tree.map(lambda _: jnp.nan, physical_state_norm)\n",
    "    phys_soft_const = eqx.tree_at(\n",
    "        lambda s: s.omega, phys_soft_const,\n",
    "        jax.nn.relu(jnp.abs(physical_state_norm.omega) - 1.0)\n",
    "    )\n",
    "    act_soft_constr = jax.nn.relu(jnp.abs(action_norm) - 1.0)\n",
    "    return phys_soft_const, act_soft_constr\n",
    "\n",
    "class Pendulum(CoreEnvironment):\n",
    "    control_state: list = eqx.field(static=True)\n",
    "    soft_constraints_logic: Callable = eqx.field(static=True)\n",
    "    \"\"\"\n",
    "    State Variables:\n",
    "        ``['theta', 'omega']``\n",
    "\n",
    "    Action Variable:\n",
    "        ``['torque']``\n",
    "\n",
    "    Initial State:\n",
    "        Unless chosen otherwise, theta=pi and omega=0\n",
    "\n",
    "    Example:\n",
    "        >>> import jax\n",
    "        >>> import jax.numpy as jnp\n",
    "        >>>\n",
    "        >>> import exciting_environments as excenvs\n",
    "        >>> from exciting_environments import GymWrapper\n",
    "        >>>\n",
    "        >>> # Create the environment\n",
    "        >>> pend=excenvs.Pendulum(batch_size=4)\n",
    "        >>>\n",
    "        >>> # Use GymWrapper for Simulation (optional)\n",
    "        >>> gym_pend=GymWrapper(env=pend)\n",
    "        >>>\n",
    "        >>> # Reset the environment with default initial values\n",
    "        >>> gym_pend.reset()\n",
    "        >>>\n",
    "        >>> # Perform step\n",
    "        >>> obs, reward, terminated,  truncated = gym_pend.step(action=jnp.ones(4).reshape(-1,1))\n",
    "        >>>\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        physical_normalizations: dict = None,\n",
    "        action_normalizations: dict = None,\n",
    "        soft_constraints: Callable = None,\n",
    "        static_params: dict = None,\n",
    "        control_state: list = None,\n",
    "        solver=diffrax.Euler(),\n",
    "        tau: float = 1e-4,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            batch_size (int): Number of parallel environment simulations. Default: 8\n",
    "            physical_normalizations (dict): Min and max values of the physical state of the environment for normalization.\n",
    "                theta (MinMaxNormalization): Rotation angle. Default: min=-jnp.pi, max=jnp.pi\n",
    "                omega (MinMaxNormalization): Angular velocity. Default: min=-10, max=10\n",
    "            action_normalizations (dict): Min and max values of the input/action for normalization.\n",
    "                torque (MinMaxNormalization): Maximum torque that can be applied to the system as an action. Default: min=-20, max=20\n",
    "            soft_constraints (Callable): Function that returns soft constraints values for state and/or action.\n",
    "            static_params (dict): Parameters of environment which do not change during simulation.\n",
    "                l (float): Length of the pendulum. Default: 1\n",
    "                m (float): Mass of the pendulum tip. Default: 1\n",
    "                g (float): Gravitational acceleration. Default: 9.81\n",
    "            control_state (list): Components of the physical state that are considered in reference tracking.\n",
    "            solver (diffrax.solver): Solver used to compute state for next step.\n",
    "            tau (float): Duration of one control step in seconds. Default: 1e-4.\n",
    "\n",
    "        Note: Attributes of MinMaxNormalization of physical_normalizations and action_normalizations as well as static_params can also be\n",
    "            passed as jnp.Array with the length of the batch_size to set different values per batch.\n",
    "        \"\"\"\n",
    "\n",
    "        if not physical_normalizations:\n",
    "            physical_normalizations = {\n",
    "                \"theta\": MinMaxNormalization(min=jnp.array(-jnp.pi), max=jnp.array(jnp.pi)),\n",
    "                \"omega\": MinMaxNormalization(min=jnp.array(-10), max=jnp.array(10)),\n",
    "            }\n",
    "\n",
    "        if not action_normalizations:\n",
    "            action_normalizations = {\"torque\": MinMaxNormalization(min=jnp.array(-20), max=jnp.array(20))}\n",
    "        \n",
    "        if not static_params:\n",
    "            static_params = {\"g\": jnp.array(9.81), \"l\": jnp.array(2), \"m\": jnp.array(1)}\n",
    "\n",
    "        if not control_state:\n",
    "            control_state = []\n",
    "        \n",
    "        logic = soft_constraints if soft_constraints else pendulum_soft_constraints\n",
    "        self.soft_constraints_logic = logic\n",
    "        self.control_state = control_state\n",
    "\n",
    "        physical_normalizations = self.PhysicalState(**physical_normalizations)\n",
    "        action_normalizations = self.Action(**action_normalizations)\n",
    "        static_params = self.StaticParams(**static_params)\n",
    "\n",
    "        env_properties = self.EnvProperties(\n",
    "            physical_normalizations=physical_normalizations,\n",
    "            action_normalizations=action_normalizations,\n",
    "            static_params=static_params,\n",
    "        )\n",
    "        super().__init__(env_properties=env_properties, tau=tau, solver=solver)\n",
    "\n",
    "    class PhysicalState(eqx.Module):\n",
    "        \"\"\"Dataclass containing the physical state of the environment.\"\"\"\n",
    "\n",
    "        theta: jax.Array\n",
    "        omega: jax.Array\n",
    "\n",
    "    class Additions(eqx.Module):\n",
    "        \"\"\"Dataclass containing additional information for simulation.\"\"\"\n",
    "\n",
    "        solver_state: tuple\n",
    "        active_solver_state: bool\n",
    "\n",
    "    class StaticParams(eqx.Module):\n",
    "        \"\"\"Dataclass containing the static parameters of the environment.\"\"\"\n",
    "\n",
    "        g: jax.Array\n",
    "        l: jax.Array\n",
    "        m: jax.Array\n",
    "\n",
    "    class Action(eqx.Module):\n",
    "        \"\"\"Dataclass containing the action, that can be applied to the environment.\"\"\"\n",
    "\n",
    "        torque: jax.Array\n",
    "\n",
    "    def _ode(self, t, y, args, action):\n",
    "        theta, omega = y\n",
    "        params = args\n",
    "        d_omega = (action(t)[0] + params.l * params.m * params.g * jnp.sin(theta)) / (params.m * (params.l) ** 2)\n",
    "        d_theta = omega\n",
    "        d_y = d_theta, d_omega\n",
    "        return d_y\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def _ode_solver_step(self, state, action):\n",
    "        \"\"\"Computes the next state by simulating one step.\n",
    "\n",
    "        Args:\n",
    "            state: The state from which to calculate state for the next step.\n",
    "            action: The action to apply to the environment.\n",
    "            static_params: Parameter of the environment, that do not change over time.\n",
    "\n",
    "        Returns:\n",
    "            next_state: The computed next state after the one step simulation.\n",
    "        \"\"\"\n",
    "        static_params = self.env_properties.static_params\n",
    "        physical_state = state.physical_state\n",
    "        args = static_params\n",
    "\n",
    "        torque = lambda t: action\n",
    "\n",
    "        vector_field = partial(self._ode, action=torque)\n",
    "\n",
    "        term = diffrax.ODETerm(vector_field)\n",
    "        t0 = 0\n",
    "        t1 = self.tau\n",
    "        y0 = tuple([physical_state.theta, physical_state.omega])\n",
    "\n",
    "        def false_fn(_):\n",
    "            return self.Additions(solver_state=self._solver.init(term, t0, t1, y0, args), active_solver_state=True)\n",
    "\n",
    "        def true_fn(_):\n",
    "            return state.additions\n",
    "\n",
    "        additions = jax.lax.cond(state.additions.active_solver_state, false_fn, true_fn, operand=None)\n",
    "        y, _, _, solver_state_k1, _ = self._solver.step(term, t0, t1, y0, args, additions.solver_state, made_jump=False)\n",
    "\n",
    "        theta_k1 = y[0]\n",
    "        omega_k1 = y[1]\n",
    "        theta_k1 = ((theta_k1 + jnp.pi) % (2 * jnp.pi)) - jnp.pi\n",
    "\n",
    "        new_physical_state = self.PhysicalState(theta=theta_k1, omega=omega_k1)\n",
    "        new_additions = self.Additions(solver_state=solver_state_k1, active_solver_state=True)\n",
    "        new_state = eqx.tree_at(lambda s: (s.physical_state, s.additions), state, (new_physical_state, new_additions))\n",
    "        return new_state\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def _ode_solver_simulate_ahead(self, init_state, actions, obs_stepsize, action_stepsize):\n",
    "        \"\"\"Computes multiple simulation steps for one batch.\n",
    "\n",
    "        Args:\n",
    "            init_state: The initial state of the simulation.\n",
    "            actions: A set of actions to be applied to the environment, the value changes every.\n",
    "            action_stepsize (shape=(n_action_steps, action_dim)).\n",
    "            static_params: The constant properties of the simulation.\n",
    "            obs_stepsize: The sampling time for the observations.\n",
    "            action_stepsize: The time between changes in the input/action.\n",
    "\n",
    "        Returns:\n",
    "            next_states: The computed states during the multiple step simulation.\n",
    "        \"\"\"\n",
    "        static_params = self.env_properties.static_params\n",
    "        init_physical_state = init_state.physical_state\n",
    "        args = static_params\n",
    "\n",
    "        def torque(t):\n",
    "            return actions[jnp.array(t / action_stepsize, int)]\n",
    "\n",
    "        vector_field = partial(self._ode, action=torque)\n",
    "\n",
    "        term = diffrax.ODETerm(vector_field)\n",
    "        t0 = 0\n",
    "        t1 = action_stepsize * actions.shape[0]\n",
    "        init_physical_state_array, _ = tree_flatten(init_physical_state)\n",
    "        y0 = tuple(init_physical_state_array)\n",
    "        saveat = diffrax.SaveAt(ts=jnp.linspace(t0, t1, 1 + int(t1 / obs_stepsize)))  #\n",
    "        sol = diffrax.diffeqsolve(\n",
    "            term,\n",
    "            self._solver,\n",
    "            t0,\n",
    "            t1,\n",
    "            dt0=obs_stepsize,\n",
    "            y0=y0,\n",
    "            args=args,\n",
    "            saveat=saveat,\n",
    "        )\n",
    "\n",
    "        theta_t = sol.ys[0]\n",
    "        omega_t = sol.ys[1]\n",
    "        obs_len = omega_t.shape[0]\n",
    "        # keep theta between -pi and pi\n",
    "        theta_t = ((theta_t + jnp.pi) % (2 * jnp.pi)) - jnp.pi\n",
    "\n",
    "        physical_states = self.PhysicalState(theta=theta_t, omega=omega_t)\n",
    "        ref = self.PhysicalState(\n",
    "            theta=jnp.full(obs_len, init_state.reference.theta),\n",
    "            omega=jnp.full(obs_len, init_state.reference.omega),\n",
    "        )\n",
    "        y0 = tuple([theta_t[-1], omega_t[-1]])\n",
    "        solver_state = self._solver.init(term, t1, t1 + self.tau, y0, args)\n",
    "        additions = self.Additions(\n",
    "            solver_state=self.repeat_values(solver_state, obs_len), active_solver_state=jnp.full(obs_len, True)\n",
    "        )\n",
    "        PRNGKey = jnp.full(obs_len, init_state.PRNGKey)\n",
    "        return self.State(\n",
    "            physical_state=physical_states,\n",
    "            PRNGKey=PRNGKey,\n",
    "            additions=additions,\n",
    "            reference=ref,\n",
    "        )\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def init_state(self, rng: chex.PRNGKey = None, vmap_helper=None):\n",
    "        env_properties = self.env_properties\n",
    "        \"\"\"Returns default or random initial state for one batch.\"\"\"\n",
    "        if rng is None:\n",
    "            phys = self.PhysicalState(\n",
    "                theta=jnp.array(1.0),\n",
    "                omega=jnp.array(0.0),\n",
    "            )\n",
    "            subkey = jnp.nan\n",
    "        else:\n",
    "            state_norm = jax.random.uniform(rng, minval=-1, maxval=1, shape=(2,))\n",
    "            phys = self.PhysicalState(\n",
    "                theta=state_norm[0],\n",
    "                omega=state_norm[1],\n",
    "            )\n",
    "            key, subkey = jax.random.split(rng)\n",
    "\n",
    "        torque = lambda t: jnp.array([0])\n",
    "\n",
    "        args = env_properties.static_params\n",
    "\n",
    "        vector_field = partial(self._ode, action=torque)\n",
    "\n",
    "        term = diffrax.ODETerm(vector_field)\n",
    "        t0 = 0\n",
    "        t1 = self.tau\n",
    "        y0 = tuple([phys.theta, phys.omega])\n",
    "\n",
    "        solver_state = self._solver.init(term, t0, t1, y0, args)\n",
    "        #dummy_solver_state = jax.tree.map(lambda x: x * jnp.nan, solver_state)\n",
    "        dummy_solver_state = jax.tree.map(lambda x: jnp.full_like(x, jnp.nan) if jnp.issubdtype(x.dtype, jnp.floating) else x, solver_state)\n",
    "\n",
    "        additions = self.Additions(solver_state=dummy_solver_state, active_solver_state=False)\n",
    "        ref = self.PhysicalState(theta=jnp.nan, omega=jnp.nan)\n",
    "        norm_state = self.State(physical_state=phys, PRNGKey=subkey, additions=additions, reference=ref)\n",
    "        return self.denormalize_state(norm_state)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def generate_reward(self, state, action):\n",
    "        \"\"\"Returns reward for one batch.\"\"\"\n",
    "        reward = 0\n",
    "        norm_state = self.normalize_state(state)\n",
    "        for name in self.control_state:\n",
    "            if name == \"theta\":\n",
    "                theta = getattr(state.physical_state, name)\n",
    "                theta_ref = getattr(state.reference, name)\n",
    "                reward += -((jnp.sin(theta) - jnp.sin(theta_ref)) ** 2 + (jnp.cos(theta) - jnp.cos(theta_ref)) ** 2)\n",
    "            else:\n",
    "                reward += -((getattr(norm_state.physical_state, name) - getattr(norm_state.reference, name)) ** 2)\n",
    "        return jnp.array([reward])\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def generate_observation(self, state):\n",
    "        \"\"\"Returns observation for one batch.\"\"\"\n",
    "        norm_state = self.normalize_state(state)\n",
    "        norm_state_phys = norm_state.physical_state\n",
    "        obs = jnp.hstack(\n",
    "            (\n",
    "                norm_state_phys.theta,\n",
    "                norm_state_phys.omega,\n",
    "            )\n",
    "        )\n",
    "        for name in self.control_state:\n",
    "            obs = jnp.hstack(\n",
    "                (\n",
    "                    obs,\n",
    "                    getattr(norm_state.reference, name),\n",
    "                )\n",
    "            )\n",
    "        return obs\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def generate_state_from_observation(self, obs, key=None):\n",
    "        env_properties = self.env_properties\n",
    "        \"\"\"Generates state from observation for one batch.\"\"\"\n",
    "        phys = self.PhysicalState(\n",
    "            theta=obs[0],\n",
    "            omega=obs[1],\n",
    "        )\n",
    "        if key is not None:\n",
    "            subkey = key\n",
    "        else:\n",
    "            subkey = jnp.nan\n",
    "\n",
    "        torque = lambda t: jnp.array([0])\n",
    "\n",
    "        args = env_properties.static_params\n",
    "\n",
    "        vector_field = partial(self._ode, action=torque)\n",
    "\n",
    "        term = diffrax.ODETerm(vector_field)\n",
    "        t0 = 0\n",
    "        t1 = self.tau\n",
    "        y0 = tuple([phys.theta, phys.omega])\n",
    "\n",
    "        solver_state = self._solver.init(term, t0, t1, y0, args)\n",
    "\n",
    "        dummy_solver_state = jax.tree.map(lambda x: x * jnp.nan, solver_state)\n",
    "\n",
    "        additions = self.Additions(solver_state=dummy_solver_state, active_solver_state=False)  # None\n",
    "        ref = self.PhysicalState(theta=jnp.nan, omega=jnp.nan)\n",
    "        new_ref = ref\n",
    "        for i, name in enumerate(self.control_state):\n",
    "            new_ref = eqx.tree_at(lambda r: getattr(r, name), new_ref, obs[2 + i])\n",
    "        norm_state = self.State(physical_state=phys, PRNGKey=subkey, additions=additions, reference=new_ref)\n",
    "        return self.denormalize_state(norm_state)\n",
    "    \n",
    "    def soft_constraints(self, state, action_norm):\n",
    "        return self.soft_constraints_logic(self, state, action_norm)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def generate_truncated(self, state):\n",
    "        \"\"\"Returns truncated information for one batch.\"\"\"\n",
    "        obs = self.generate_observation(state)\n",
    "        return jnp.abs(obs) > 1\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def generate_terminated(self, state, reward):\n",
    "        \"\"\"Returns terminated information for one batch.\"\"\"\n",
    "        return reward == 0\n",
    "\n",
    "    @property\n",
    "    def obs_description(self):\n",
    "        return np.hstack(\n",
    "            [\n",
    "                np.array([\"theta\", \"omega\"]),\n",
    "                np.array([name + \"_ref\" for name in self.control_state]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def action_description(self):\n",
    "        return np.array([\"torque\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a2042cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pend_env = Pendulum(solver=diffrax.Heun())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1a887104",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, state = pend_env.reset(jax.random.PRNGKey(123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c28627",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=jax.random.PRNGKey(1234)\n",
    "obs, state = pend_env.reset(key)\n",
    "generated_observations = []\n",
    "generated_actions= []\n",
    "generated_observations.append(obs)\n",
    "for i in range(10000):\n",
    "    key,subkey= jax.random.split(key)\n",
    "    action = jax.random.uniform(subkey,(1,),minval=-1,maxval=1)\n",
    "    obs, state = pend_env.step(state, action)\n",
    "    generated_actions.append(action)\n",
    "    generated_observations.append(obs)\n",
    "generated_observations = jnp.array(generated_observations)\n",
    "generated_actions = jnp.array(generated_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8839f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(jnp.sin(generated_observations[:,0]),-jnp.cos(generated_observations[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9fc9d73",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mismatch custom node data: (<equinox._module._flatten._Missing object at 0x7f28f320b3d0>, Tsit5(), functools.partial(<function pendulum_soft_constraints at 0x7f271c6245e0>, Partial(\n  func=_JitWrapper(\n    fn='CoreEnvironment.normalize_state',\n    filter_warning=False,\n    donate_first=False,\n    donate_rest=False\n  ),\n  args=(\n    Pendulum(\n      batch_size=1,\n      tau=0.0001,\n      _solver=Tsit5(),\n      env_properties=CoreEnvironment.EnvProperties(\n        physical_normalizations=Pendulum.PhysicalState(\n          theta=MinMaxNormalization(min=weak_f64[], max=weak_f64[]),\n          omega=MinMaxNormalization(min=weak_i64[], max=weak_i64[])\n        ),\n        action_normalizations=Pendulum.Action(\n          torque=MinMaxNormalization(min=weak_i64[], max=weak_i64[])\n        ),\n        static_params=Pendulum.StaticParams(\n          g=weak_f64[], l=weak_f64[], m=weak_f64[]\n        )\n      ),\n      in_axes_env_properties=CoreEnvironment.EnvProperties(\n        physical_normalizations=Pendulum.PhysicalState(\n          theta=MinMaxNormalization(min=None, max=None),\n          omega=MinMaxNormalization(min=None, max=None)\n        ),\n        action_normalizations=Pendulum.Action(\n          torque=MinMaxNormalization(min=None, max=None)\n        ),\n        static_params=Pendulum.StaticParams(g=None, l=None, m=None)\n      ),\n      action_dim=1,\n      physical_state_dim=2,\n      control_state=[],\n      soft_constraints=partial(\n        <function pendulum_soft_constraints>, <recursive>\n      )\n    ),\n  ),\n  keywords={}\n))) != (<equinox._module._flatten._Missing object at 0x7f28f320b3d0>, Tsit5(), functools.partial(<function pendulum_soft_constraints at 0x7f271c6245e0>, Partial(\n  func=_JitWrapper(\n    fn='CoreEnvironment.normalize_state',\n    filter_warning=False,\n    donate_first=False,\n    donate_rest=False\n  ),\n  args=(\n    Pendulum(\n      batch_size=1,\n      tau=0.0001,\n      _solver=Tsit5(),\n      env_properties=CoreEnvironment.EnvProperties(\n        physical_normalizations=Pendulum.PhysicalState(\n          theta=MinMaxNormalization(min=weak_f64[], max=weak_f64[]),\n          omega=MinMaxNormalization(min=weak_i64[], max=weak_i64[])\n        ),\n        action_normalizations=Pendulum.Action(\n          torque=MinMaxNormalization(min=weak_i64[], max=weak_i64[])\n        ),\n        static_params=Pendulum.StaticParams(\n          g=weak_f64[], l=weak_f64[], m=weak_f64[]\n        )\n      ),\n      in_axes_env_properties=CoreEnvironment.EnvProperties(\n        physical_normalizations=Pendulum.PhysicalState(\n          theta=MinMaxNormalization(min=None, max=None),\n          omega=MinMaxNormalization(min=None, max=None)\n        ),\n        action_normalizations=Pendulum.Action(\n          torque=MinMaxNormalization(min=None, max=None)\n        ),\n        static_params=Pendulum.StaticParams(g=None, l=None, m=None)\n      ),\n      action_dim=1,\n      physical_state_dim=2,\n      control_state=[],\n      soft_constraints=partial(\n        <function pendulum_soft_constraints>, <recursive>\n      )\n    ),\n  ),\n  keywords={}\n))); value: Pendulum(\n  batch_size=None,\n  tau=None,\n  _solver=Tsit5(),\n  env_properties=CoreEnvironment.EnvProperties(\n    physical_normalizations=Pendulum.PhysicalState(\n      theta=MinMaxNormalization(min=weak_f64[], max=weak_f64[]),\n      omega=MinMaxNormalization(min=weak_i64[], max=weak_i64[])\n    ),\n    action_normalizations=Pendulum.Action(\n      torque=MinMaxNormalization(min=weak_i64[], max=weak_i64[])\n    ),\n    static_params=Pendulum.StaticParams(\n      g=weak_f64[], l=weak_f64[], m=weak_f64[]\n    )\n  ),\n  in_axes_env_properties=CoreEnvironment.EnvProperties(\n    physical_normalizations=Pendulum.PhysicalState(\n      theta=MinMaxNormalization(min=None, max=None),\n      omega=MinMaxNormalization(min=None, max=None)\n    ),\n    action_normalizations=Pendulum.Action(\n      torque=MinMaxNormalization(min=None, max=None)\n    ),\n    static_params=Pendulum.StaticParams(g=None, l=None, m=None)\n  ),\n  action_dim=None,\n  physical_state_dim=None,\n  control_state=[],\n  soft_constraints=partial(\n    <function pendulum_soft_constraints>,\n    Partial(\n      func=_JitWrapper(\n        fn='CoreEnvironment.normalize_state',\n        filter_warning=False,\n        donate_first=False,\n        donate_rest=False\n      ),\n      args=(\n        Pendulum(\n          batch_size=1,\n          tau=0.0001,\n          _solver=Tsit5(),\n          env_properties=CoreEnvironment.EnvProperties(\n            physical_normalizations=Pendulum.PhysicalState(\n              theta=MinMaxNormalization(min=weak_f64[], max=weak_f64[]),\n              omega=MinMaxNormalization(min=weak_i64[], max=weak_i64[])\n            ),\n            action_normalizations=Pendulum.Action(\n              torque=MinMaxNormalization(min=weak_i64[], max=weak_i64[])\n            ),\n            static_params=Pendulum.StaticParams(\n              g=weak_f64[], l=weak_f64[], m=weak_f64[]\n            )\n          ),\n          in_axes_env_properties=CoreEnvironment.EnvProperties(\n            physical_normalizations=Pendulum.PhysicalState(\n              theta=MinMaxNormalization(min=None, max=None),\n              omega=MinMaxNormalization(min=None, max=None)\n            ),\n            action_normalizations=Pendulum.Action(\n              torque=MinMaxNormalization(min=None, max=None)\n            ),\n            static_params=Pendulum.StaticParams(g=None, l=None, m=None)\n          ),\n          action_dim=1,\n          physical_state_dim=2,\n          control_state=[],\n          soft_constraints=<recursive>\n        ),\n      ),\n      keywords={}\n    )\n  )\n).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m envs = [Pendulum(solver=diffrax.Tsit5(),batch_size=\u001b[32m1\u001b[39m,static_params={\u001b[33m\"\u001b[39m\u001b[33mg\u001b[39m\u001b[33m\"\u001b[39m: jnp.array(\u001b[32m9.81\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33ml\u001b[39m\u001b[33m\"\u001b[39m: jnp.array(\u001b[38;5;28mfloat\u001b[39m(i+\u001b[32m1\u001b[39m)),  \u001b[33m\"\u001b[39m\u001b[33mm\u001b[39m\u001b[33m\"\u001b[39m: jnp.array(\u001b[32m1.0\u001b[39m)}) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m4\u001b[39m)]\n\u001b[32m      4\u001b[39m trainables, statics = \u001b[38;5;28mzip\u001b[39m(*(eqx.partition(m, eqx.is_array) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m envs))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m batched_trainables = \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrainables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m batched_module = eqx.combine(batched_trainables, statics[\u001b[32m0\u001b[39m])\n\u001b[32m     10\u001b[39m actions = jnp.ones((\u001b[32m4\u001b[39m, \u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/venv_excenv_eqx/lib/python3.11/site-packages/jax/_src/tree.py:155\u001b[39m, in \u001b[36mmap\u001b[39m\u001b[34m(f, tree, is_leaf, *rest)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(f: Callable[..., Any],\n\u001b[32m    116\u001b[39m         tree: Any,\n\u001b[32m    117\u001b[39m         *rest: Any,\n\u001b[32m    118\u001b[39m         is_leaf: Callable[[Any], \u001b[38;5;28mbool\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> Any:\n\u001b[32m    119\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Maps a multi-input function over pytree args to produce a new pytree.\u001b[39;00m\n\u001b[32m    120\u001b[39m \n\u001b[32m    121\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    153\u001b[39m \u001b[33;03m    - :func:`jax.tree.reduce`\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree_util\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mrest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/venv_excenv_eqx/lib/python3.11/site-packages/jax/_src/tree_util.py:368\u001b[39m, in \u001b[36mtree_map\u001b[39m\u001b[34m(f, tree, is_leaf, *rest)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Alias of :func:`jax.tree.map`.\"\"\"\u001b[39;00m\n\u001b[32m    367\u001b[39m leaves, treedef = tree_flatten(tree, is_leaf)\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m all_leaves = [leaves] + \u001b[43m[\u001b[49m\u001b[43mtreedef\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflatten_up_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrest\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m treedef.unflatten(f(*xs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(*all_leaves))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/venv_excenv_eqx/lib/python3.11/site-packages/jax/_src/tree_util.py:368\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Alias of :func:`jax.tree.map`.\"\"\"\u001b[39;00m\n\u001b[32m    367\u001b[39m leaves, treedef = tree_flatten(tree, is_leaf)\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m all_leaves = [leaves] + [\u001b[43mtreedef\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflatten_up_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m treedef.unflatten(f(*xs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(*all_leaves))\n",
      "\u001b[31mValueError\u001b[39m: Mismatch custom node data: (<equinox._module._flatten._Missing object at 0x7f28f320b3d0>, Tsit5(), functools.partial(<function pendulum_soft_constraints at 0x7f271c6245e0>, Partial(\n  func=_JitWrapper(\n    fn='CoreEnvironment.normalize_state',\n    filter_warning=False,\n    donate_first=False,\n    donate_rest=False\n  ),\n  args=(\n    Pendulum(\n      batch_size=1,\n      tau=0.0001,\n      _solver=Tsit5(),\n      env_properties=CoreEnvironment.EnvProperties(\n        physical_normalizations=Pendulum.PhysicalState(\n          theta=MinMaxNormalization(min=weak_f64[], max=weak_f64[]),\n          omega=MinMaxNormalization(min=weak_i64[], max=weak_i64[])\n        ),\n        action_normalizations=Pendulum.Action(\n          torque=MinMaxNormalization(min=weak_i64[], max=weak_i64[])\n        ),\n        static_params=Pendulum.StaticParams(\n          g=weak_f64[], l=weak_f64[], m=weak_f64[]\n        )\n      ),\n      in_axes_env_properties=CoreEnvironment.EnvProperties(\n        physical_normalizations=Pendulum.PhysicalState(\n          theta=MinMaxNormalization(min=None, max=None),\n          omega=MinMaxNormalization(min=None, max=None)\n        ),\n        action_normalizations=Pendulum.Action(\n          torque=MinMaxNormalization(min=None, max=None)\n        ),\n        static_params=Pendulum.StaticParams(g=None, l=None, m=None)\n      ),\n      action_dim=1,\n      physical_state_dim=2,\n      control_state=[],\n      soft_constraints=partial(\n        <function pendulum_soft_constraints>, <recursive>\n      )\n    ),\n  ),\n  keywords={}\n))) != (<equinox._module._flatten._Missing object at 0x7f28f320b3d0>, Tsit5(), functools.partial(<function pendulum_soft_constraints at 0x7f271c6245e0>, Partial(\n  func=_JitWrapper(\n    fn='CoreEnvironment.normalize_state',\n    filter_warning=False,\n    donate_first=False,\n    donate_rest=False\n  ),\n  args=(\n    Pendulum(\n      batch_size=1,\n      tau=0.0001,\n      _solver=Tsit5(),\n      env_properties=CoreEnvironment.EnvProperties(\n        physical_normalizations=Pendulum.PhysicalState(\n          theta=MinMaxNormalization(min=weak_f64[], max=weak_f64[]),\n          omega=MinMaxNormalization(min=weak_i64[], max=weak_i64[])\n        ),\n        action_normalizations=Pendulum.Action(\n          torque=MinMaxNormalization(min=weak_i64[], max=weak_i64[])\n        ),\n        static_params=Pendulum.StaticParams(\n          g=weak_f64[], l=weak_f64[], m=weak_f64[]\n        )\n      ),\n      in_axes_env_properties=CoreEnvironment.EnvProperties(\n        physical_normalizations=Pendulum.PhysicalState(\n          theta=MinMaxNormalization(min=None, max=None),\n          omega=MinMaxNormalization(min=None, max=None)\n        ),\n        action_normalizations=Pendulum.Action(\n          torque=MinMaxNormalization(min=None, max=None)\n        ),\n        static_params=Pendulum.StaticParams(g=None, l=None, m=None)\n      ),\n      action_dim=1,\n      physical_state_dim=2,\n      control_state=[],\n      soft_constraints=partial(\n        <function pendulum_soft_constraints>, <recursive>\n      )\n    ),\n  ),\n  keywords={}\n))); value: Pendulum(\n  batch_size=None,\n  tau=None,\n  _solver=Tsit5(),\n  env_properties=CoreEnvironment.EnvProperties(\n    physical_normalizations=Pendulum.PhysicalState(\n      theta=MinMaxNormalization(min=weak_f64[], max=weak_f64[]),\n      omega=MinMaxNormalization(min=weak_i64[], max=weak_i64[])\n    ),\n    action_normalizations=Pendulum.Action(\n      torque=MinMaxNormalization(min=weak_i64[], max=weak_i64[])\n    ),\n    static_params=Pendulum.StaticParams(\n      g=weak_f64[], l=weak_f64[], m=weak_f64[]\n    )\n  ),\n  in_axes_env_properties=CoreEnvironment.EnvProperties(\n    physical_normalizations=Pendulum.PhysicalState(\n      theta=MinMaxNormalization(min=None, max=None),\n      omega=MinMaxNormalization(min=None, max=None)\n    ),\n    action_normalizations=Pendulum.Action(\n      torque=MinMaxNormalization(min=None, max=None)\n    ),\n    static_params=Pendulum.StaticParams(g=None, l=None, m=None)\n  ),\n  action_dim=None,\n  physical_state_dim=None,\n  control_state=[],\n  soft_constraints=partial(\n    <function pendulum_soft_constraints>,\n    Partial(\n      func=_JitWrapper(\n        fn='CoreEnvironment.normalize_state',\n        filter_warning=False,\n        donate_first=False,\n        donate_rest=False\n      ),\n      args=(\n        Pendulum(\n          batch_size=1,\n          tau=0.0001,\n          _solver=Tsit5(),\n          env_properties=CoreEnvironment.EnvProperties(\n            physical_normalizations=Pendulum.PhysicalState(\n              theta=MinMaxNormalization(min=weak_f64[], max=weak_f64[]),\n              omega=MinMaxNormalization(min=weak_i64[], max=weak_i64[])\n            ),\n            action_normalizations=Pendulum.Action(\n              torque=MinMaxNormalization(min=weak_i64[], max=weak_i64[])\n            ),\n            static_params=Pendulum.StaticParams(\n              g=weak_f64[], l=weak_f64[], m=weak_f64[]\n            )\n          ),\n          in_axes_env_properties=CoreEnvironment.EnvProperties(\n            physical_normalizations=Pendulum.PhysicalState(\n              theta=MinMaxNormalization(min=None, max=None),\n              omega=MinMaxNormalization(min=None, max=None)\n            ),\n            action_normalizations=Pendulum.Action(\n              torque=MinMaxNormalization(min=None, max=None)\n            ),\n            static_params=Pendulum.StaticParams(g=None, l=None, m=None)\n          ),\n          action_dim=1,\n          physical_state_dim=2,\n          control_state=[],\n          soft_constraints=<recursive>\n        ),\n      ),\n      keywords={}\n    )\n  )\n)."
     ]
    }
   ],
   "source": [
    "keys = jax.random.split(jax.random.PRNGKey(0), 3)\n",
    "envs = [Pendulum(solver=diffrax.Tsit5(),batch_size=1,static_params={\"g\": jnp.array(9.81), \"l\": jnp.array(float(i+1)),  \"m\": jnp.array(1.0)}) for i in range(4)]\n",
    "\n",
    "trainables, statics = zip(*(eqx.partition(m, eqx.is_array) for m in envs))\n",
    "\n",
    "batched_trainables = jax.tree.map(lambda *xs: jnp.stack(xs), *trainables)\n",
    "\n",
    "batched_module = eqx.combine(batched_trainables, statics[0])\n",
    "\n",
    "actions = jnp.ones((4, 1))\n",
    "key=jax.random.PRNGKey(1234)\n",
    "keys = jax.random.split(key,num=4)\n",
    "obs, states = batched_module.reset(keys)\n",
    "\n",
    "#obs, states = batched_module.step(states,jnp.array([0,2,5,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bf6092b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stack requires ndarray or scalar arguments, got <class 'function'> at position 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[132]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#envs = [Pendulum(solver=diffrax.Euler(),batch_size=1,static_params={\"g\": jnp.array(9.81), \"l\": jnp.array(float(1+i)),  \"m\": jnp.array(1.0)}) for i in range(4)]\u001b[39;00m\n\u001b[32m      3\u001b[39m envs = [Pendulum(solver=diffrax.Euler(),control_state=[\u001b[33m\"\u001b[39m\u001b[33mtheta\u001b[39m\u001b[33m\"\u001b[39m],tau=\u001b[32m1e-2\u001b[39m,static_params={\u001b[33m\"\u001b[39m\u001b[33mg\u001b[39m\u001b[33m\"\u001b[39m: jnp.array(\u001b[32m9.81\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33ml\u001b[39m\u001b[33m\"\u001b[39m: jnp.array(\u001b[38;5;28mfloat\u001b[39m(\u001b[32m1\u001b[39m)),  \u001b[33m\"\u001b[39m\u001b[33mm\u001b[39m\u001b[33m\"\u001b[39m: jnp.array(\u001b[32m1.0\u001b[39m)}),Pendulum(solver=diffrax.Euler(),control_state=[\u001b[33m\"\u001b[39m\u001b[33mtheta\u001b[39m\u001b[33m\"\u001b[39m],tau=\u001b[32m1e-3\u001b[39m,static_params={\u001b[33m\"\u001b[39m\u001b[33mg\u001b[39m\u001b[33m\"\u001b[39m: jnp.array(\u001b[32m9.81\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33ml\u001b[39m\u001b[33m\"\u001b[39m: jnp.array(\u001b[38;5;28mfloat\u001b[39m(\u001b[32m2\u001b[39m)),  \u001b[33m\"\u001b[39m\u001b[33mm\u001b[39m\u001b[33m\"\u001b[39m: jnp.array(\u001b[32m1.0\u001b[39m)})]\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m batched_envs = \u001b[43mjax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43menvs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#batched_envs.reset(rng=jax.random.PRNGKey(321))\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/venv_excenv_eqx/lib/python3.11/site-packages/jax/_src/tree.py:155\u001b[39m, in \u001b[36mmap\u001b[39m\u001b[34m(f, tree, is_leaf, *rest)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(f: Callable[..., Any],\n\u001b[32m    116\u001b[39m         tree: Any,\n\u001b[32m    117\u001b[39m         *rest: Any,\n\u001b[32m    118\u001b[39m         is_leaf: Callable[[Any], \u001b[38;5;28mbool\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> Any:\n\u001b[32m    119\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Maps a multi-input function over pytree args to produce a new pytree.\u001b[39;00m\n\u001b[32m    120\u001b[39m \n\u001b[32m    121\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    153\u001b[39m \u001b[33;03m    - :func:`jax.tree.reduce`\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree_util\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mrest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/venv_excenv_eqx/lib/python3.11/site-packages/jax/_src/tree_util.py:369\u001b[39m, in \u001b[36mtree_map\u001b[39m\u001b[34m(f, tree, is_leaf, *rest)\u001b[39m\n\u001b[32m    367\u001b[39m leaves, treedef = tree_flatten(tree, is_leaf)\n\u001b[32m    368\u001b[39m all_leaves = [leaves] + [treedef.flatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreedef\u001b[49m\u001b[43m.\u001b[49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mall_leaves\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/venv_excenv_eqx/lib/python3.11/site-packages/jax/_src/tree_util.py:369\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    367\u001b[39m leaves, treedef = tree_flatten(tree, is_leaf)\n\u001b[32m    368\u001b[39m all_leaves = [leaves] + [treedef.flatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m treedef.unflatten(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(*all_leaves))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[132]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#envs = [Pendulum(solver=diffrax.Euler(),batch_size=1,static_params={\"g\": jnp.array(9.81), \"l\": jnp.array(float(1+i)),  \"m\": jnp.array(1.0)}) for i in range(4)]\u001b[39;00m\n\u001b[32m      3\u001b[39m envs = [Pendulum(solver=diffrax.Euler(),control_state=[\u001b[33m\"\u001b[39m\u001b[33mtheta\u001b[39m\u001b[33m\"\u001b[39m],tau=\u001b[32m1e-2\u001b[39m,static_params={\u001b[33m\"\u001b[39m\u001b[33mg\u001b[39m\u001b[33m\"\u001b[39m: jnp.array(\u001b[32m9.81\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33ml\u001b[39m\u001b[33m\"\u001b[39m: jnp.array(\u001b[38;5;28mfloat\u001b[39m(\u001b[32m1\u001b[39m)),  \u001b[33m\"\u001b[39m\u001b[33mm\u001b[39m\u001b[33m\"\u001b[39m: jnp.array(\u001b[32m1.0\u001b[39m)}),Pendulum(solver=diffrax.Euler(),control_state=[\u001b[33m\"\u001b[39m\u001b[33mtheta\u001b[39m\u001b[33m\"\u001b[39m],tau=\u001b[32m1e-3\u001b[39m,static_params={\u001b[33m\"\u001b[39m\u001b[33mg\u001b[39m\u001b[33m\"\u001b[39m: jnp.array(\u001b[32m9.81\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33ml\u001b[39m\u001b[33m\"\u001b[39m: jnp.array(\u001b[38;5;28mfloat\u001b[39m(\u001b[32m2\u001b[39m)),  \u001b[33m\"\u001b[39m\u001b[33mm\u001b[39m\u001b[33m\"\u001b[39m: jnp.array(\u001b[32m1.0\u001b[39m)})]\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m batched_envs = jax.tree.map(\u001b[38;5;28;01mlambda\u001b[39;00m *args: \u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m, *envs)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#batched_envs.reset(rng=jax.random.PRNGKey(321))\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/venv_excenv_eqx/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py:4433\u001b[39m, in \u001b[36mstack\u001b[39m\u001b[34m(arrays, axis, out, dtype)\u001b[39m\n\u001b[32m   4431\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m concatenate(expand_dims(arrays, axis + \u001b[32m1\u001b[39m), axis=axis, dtype=dtype)\n\u001b[32m   4432\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4433\u001b[39m   arrays = \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mensure_arraylike_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstack\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4434\u001b[39m   shape0 = np.shape(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m   4435\u001b[39m   axis = _canonicalize_axis(axis, \u001b[38;5;28mlen\u001b[39m(shape0) + \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/venv_excenv_eqx/lib/python3.11/site-packages/jax/_src/numpy/util.py:160\u001b[39m, in \u001b[36mensure_arraylike_tuple\u001b[39m\u001b[34m(fun_name, tup)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mensure_arraylike_tuple\u001b[39m(fun_name: \u001b[38;5;28mstr\u001b[39m, tup: Sequence[Any]) -> \u001b[38;5;28mtuple\u001b[39m[Array, ...]:\n\u001b[32m    156\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Check that argument elements are arraylike and convert to a tuple of arrays.\u001b[39;00m\n\u001b[32m    157\u001b[39m \n\u001b[32m    158\u001b[39m \u001b[33;03m  This is useful because ensure_arraylike with a single argument returns a single array.\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m   \u001b[43mcheck_arraylike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(_arraylike_asarray(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m tup)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/venv_excenv_eqx/lib/python3.11/site-packages/jax/_src/numpy/util.py:175\u001b[39m, in \u001b[36mcheck_arraylike\u001b[39m\u001b[34m(fun_name, emit_warning, stacklevel, *args)\u001b[39m\n\u001b[32m    172\u001b[39m   warnings.warn(msg + \u001b[33m\"\u001b[39m\u001b[33m In a future JAX release this will be an error.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    173\u001b[39m                 category=\u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=stacklevel)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg.format(fun_name, \u001b[38;5;28mtype\u001b[39m(arg), pos))\n",
      "\u001b[31mTypeError\u001b[39m: stack requires ndarray or scalar arguments, got <class 'function'> at position 0."
     ]
    }
   ],
   "source": [
    "\n",
    "keys = jax.random.split(jax.random.PRNGKey(0), 2)\n",
    "#envs = [Pendulum(solver=diffrax.Euler(),batch_size=1,static_params={\"g\": jnp.array(9.81), \"l\": jnp.array(float(1+i)),  \"m\": jnp.array(1.0)}) for i in range(4)]\n",
    "envs = [Pendulum(solver=diffrax.Euler(),control_state=[\"theta\"],tau=1e-2,static_params={\"g\": jnp.array(9.81), \"l\": jnp.array(float(1)),  \"m\": jnp.array(1.0)}),Pendulum(solver=diffrax.Euler(),control_state=[\"theta\"],tau=1e-3,static_params={\"g\": jnp.array(9.81), \"l\": jnp.array(float(2)),  \"m\": jnp.array(1.0)})]\n",
    "batched_envs = jax.tree.map(lambda *args: jnp.stack(args), *envs)\n",
    "#batched_envs.reset(rng=jax.random.PRNGKey(321))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d6f18b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = jax.random.split(jax.random.PRNGKey(0), 2)\n",
    "obs, states = jax.vmap(lambda e,k: e.reset(k))(batched_envs,keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d88c8f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.93977834, -0.36941787],\n",
       "       [-0.83848137,  0.84792387],\n",
       "       [ 0.30408614,  0.75913929],\n",
       "       [ 0.50112481, -0.04066952]], dtype=float64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = jnp.ones((4,1))\n",
    "\n",
    "next_obs, next_states = jax.vmap(\n",
    "    lambda e, s, a: e.step(s, a)\n",
    ")(batched_envs, states, actions)\n",
    "next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f1a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=jax.random.PRNGKey(123)\n",
    "obs, state = pend_env.reset(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f226dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "envs = [Pendulum(batch_size=1,static_params={\"g\": 9.81, \"l\": float(i+1), \"m\": 1.0}) for i in range(4)]\n",
    "actions = jnp.ones((4, 1))  # eine Action pro Environment\n",
    "key=jax.random.PRNGKey(1234)\n",
    "obs, state = pend_env.reset(key)\n",
    "# vmap ber Module (0. Dimension) und Actions\n",
    "# obs, states = jax.vmap(lambda env, a: env.step(state, a))(envs, actions)\n",
    "keys = jax.random.split(key,num=4)\n",
    "states = jax.vmap(lambda e, k: e.reset(k)[1])(envs, keys)\n",
    "obs_batch, states_batch = jax.vmap(lambda e, s, a: e.step(s, a))(envs, states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5d20b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(eqx.Module):\n",
    "    weight: jax.Array\n",
    "    bias: jax.Array\n",
    "    config: dict = eqx.field(static=True)  # static, nicht gemappt\n",
    "\n",
    "# Erzeuge mehrere Module\n",
    "mods = [MyModule(weight=jnp.array(i), bias=jnp.array(i*2),config={}) for i in range(4)]\n",
    "\n",
    "\n",
    "# vmap ber die batch dimension\n",
    "def forward(mod, x):\n",
    "    return mod.weight * x + mod.bias\n",
    "\n",
    "xs = jnp.ones(4)\n",
    "out = jax.vmap(forward)(mods, xs)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54812ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = [\n",
    "    Pendulum(batch_size=1, static_params={\"g\": 9.81, \"l\": float(i+1), \"m\": 1.0})\n",
    "    for i in range(4)\n",
    "]\n",
    "\n",
    "# 2. Partitioniere alles in Arrays vs. Rest\n",
    "trainables_list, statics_list = zip(*(eqx.partition(env, eqx.is_array) for env in envs))\n",
    "\n",
    "# 3. Jetzt nur die Arrays selbst stacken, keine Sub-Module!\n",
    "def stack_arrays(*args):\n",
    "    return jax.tree_map(lambda *x: jnp.stack(x), *args)\n",
    "\n",
    "batched_trainables = stack_arrays(*trainables_list)\n",
    "\n",
    "# 4. Einen \"batched Module\" erzeugen\n",
    "batched_env = eqx.combine(batched_trainables, statics_list[0])  # statics[0] reicht\n",
    "\n",
    "# 5. Actions vorbereiten\n",
    "actions = jnp.ones((4, 1))\n",
    "key = jax.random.PRNGKey(1234)\n",
    "\n",
    "# 6. Reset (funktioniert fr batched_env)\n",
    "obs, state = batched_env.reset( key)\n",
    "\n",
    "# 7. vmap ber Actions\n",
    "batched_step = jax.vmap(lambda a: batched_env.step(state, a))\n",
    "obs, states = batched_step(actions)\n",
    "\n",
    "print(\"obs:\", obs)\n",
    "print(\"states:\", states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b34fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "class SimpleModule(eqx.Module):\n",
    "    weight: jnp.ndarray\n",
    "    bias: jnp.ndarray\n",
    "\n",
    "    def __init__(self, key):\n",
    "        k1, k2 = jax.random.split(key)\n",
    "        self.weight = jax.random.normal(k1, (3, 3))\n",
    "        self.bias = jax.random.normal(k2, (3,))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return jnp.dot(self.weight, x) + self.bias\n",
    "\n",
    "\n",
    "keys = jax.random.split(jax.random.PRNGKey(0), 3)\n",
    "modules = [SimpleModule(k) for k in keys]\n",
    "\n",
    "trainables, statics = zip(*(eqx.partition(m, eqx.is_array) for m in modules))\n",
    "\n",
    "batched_trainables = jax.tree.map(lambda *xs: jnp.stack(xs), *trainables)\n",
    "\n",
    "batched_module = eqx.combine(batched_trainables, statics[0])\n",
    "\n",
    "x_inputs = jnp.ones((3, 3)) \n",
    "batched_apply = jax.vmap(lambda m, x: jnp.sum(m(x)), in_axes=(None, 0))\n",
    "\n",
    "results = batched_apply(batched_module, x_inputs)\n",
    "\n",
    "print(\"Results:\", results)   # shape (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a826f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "\n",
    "# envs = [Pendulum(...), Pendulum(...), ...]\n",
    "batched_env = eqx.combine(envs)\n",
    "\n",
    "actions = jnp.ones((4, 1))  # eine Action pro Env\n",
    "\n",
    "# state muss ggf. auch gebatched sein\n",
    "obs, states = jax.vmap(lambda env, a: env.step(state, a))(\n",
    "    batched_env, actions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7a023b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_excenv_eqx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
